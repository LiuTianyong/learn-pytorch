{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization\n",
    "```\n",
    "称为批标准化。批是指一批数据，通常为 mini-batch；标准化是处理后的数据服从$N(0,1)$的正态分布。\n",
    "批标准化的优点有如下：\n",
    "    可以使用更大的学习率，加速模型收敛\n",
    "    可以不用精心设计权值初始化\n",
    "    可以不用 dropout 或者较小的 dropout\n",
    "    可以不用 L2 或者较小的 weight decay\n",
    "    可以不用 LRN (local response normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设输入的 mini-batch 数据是$\\mathcal{B}=\\left{x_{1 \\dots m}\\right}$，Batch Normalization 的可学习参数是$\\gamma, \\beta$，步骤如下：\n",
    "求 mini-batch 的均值：$\\mu{\\mathcal{B}} \\leftarrow \\frac{1}{m} \\sum{i=1}^{m} x_{i}$\n",
    "求 mini-batch 的方差：$\\sigma{\\mathcal{B}}^{2} \\leftarrow \\frac{1}{m} \\sum{i=1}\\left(x{i}-\\mu{\\mathcal{B}}\\right)^{2}$\n",
    "标准化：$\\widehat{x}{i} \\leftarrow \\frac{x{i}-\\mu{\\mathcal{B}}}{\\sqrt{\\sigma{B}^{2}+\\epsilon}}$，其中$\\epsilon$ 是放置分母为 0 的一个数\n",
    "affine transform(缩放和平移)：$y{i} \\leftarrow \\gamma \\widehat{x}{i}+\\beta \\equiv \\mathrm{B} \\mathrm{N}{\\gamma, \\beta}\\left(x{i}\\right)$，这个操作可以增强模型的 capacity，也就是让模型自己判断是否要对数据进行标准化，进行多大程度的标准化。如果$\\gamma= \\sqrt{\\sigma{B}^{2}}$，$\\beta=\\mu{\\mathcal{B}}$，那么就实现了恒等映射。\n",
    "\n",
    "Batch Normalization 的提出主要是为了解决 Internal Covariate Shift (ICS)。在训练过程中，数据需要经过多层的网络，如果数据在前向传播的过程中，尺度发生了变化，可能会导致梯度爆炸或者梯度消失，从而导致模型难以收敛。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "通用函数\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def transform_invert(img_, transform_train):\n",
    "    \"\"\"\n",
    "    将data 进行反transfrom操作\n",
    "    :param img_: tensor\n",
    "    :param transform_train: torchvision.transforms\n",
    "    :return: PIL image\n",
    "    \"\"\"\n",
    "    if 'Normalize' in str(transform_train):\n",
    "        norm_transform = list(filter(lambda x: isinstance(x, transforms.Normalize), transform_train.transforms))\n",
    "        mean = torch.tensor(norm_transform[0].mean, dtype=img_.dtype, device=img_.device)\n",
    "        std = torch.tensor(norm_transform[0].std, dtype=img_.dtype, device=img_.device)\n",
    "        img_.mul_(std[:, None, None]).add_(mean[:, None, None])\n",
    "\n",
    "    img_ = img_.transpose(0, 2).transpose(0, 1)  # C*H*W --> H*W*C\n",
    "    if 'ToTensor' in str(transform_train):\n",
    "        img_ = img_.detach().numpy() * 255\n",
    "\n",
    "    if img_.shape[2] == 3:\n",
    "        img_ = Image.fromarray(img_.astype('uint8')).convert('RGB')\n",
    "    elif img_.shape[2] == 1:\n",
    "        img_ = Image.fromarray(img_.astype('uint8').squeeze())\n",
    "    else:\n",
    "        raise Exception(\"Invalid img shape, expected 1 or 3 in axis 2, but got {}!\".format(img_.shape[2]) )\n",
    "\n",
    "    return img_\n",
    "\n",
    "\n",
    "def set_seed(seed=1):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers:0, std:0.3342404067516327\n",
      "layers:1, std:0.13787390291690826\n",
      "layers:2, std:0.05783054977655411\n",
      "layers:3, std:0.02498556487262249\n",
      "layers:4, std:0.009679116308689117\n",
      "layers:5, std:0.00407979404553771\n",
      "layers:6, std:0.0016723505686968565\n",
      "layers:7, std:0.000768698868341744\n",
      "layers:8, std:0.00034261963446624577\n",
      "layers:9, std:0.00013652061170432717\n",
      "layers:10, std:5.5681408412056044e-05\n",
      "layers:11, std:2.116799987561535e-05\n",
      "layers:12, std:7.95504547568271e-06\n",
      "layers:13, std:3.492599489618442e-06\n",
      "layers:14, std:1.3507375342669548e-06\n",
      "layers:15, std:5.237313303041446e-07\n",
      "layers:16, std:2.1298420449511468e-07\n",
      "layers:17, std:9.138079093418128e-08\n",
      "layers:18, std:3.205319742960455e-08\n",
      "layers:19, std:1.1857623327671263e-08\n",
      "layers:20, std:4.69678340664359e-09\n",
      "layers:21, std:1.6383255863061663e-09\n",
      "layers:22, std:7.384883260463937e-10\n",
      "layers:23, std:2.922064257226964e-10\n",
      "layers:24, std:1.1803433230817006e-10\n",
      "layers:25, std:5.002631989214912e-11\n",
      "layers:26, std:2.1812036551938085e-11\n",
      "layers:27, std:8.490535531591181e-12\n",
      "layers:28, std:3.71682589220268e-12\n",
      "layers:29, std:1.5252006472024626e-12\n",
      "layers:30, std:6.126969591402354e-13\n",
      "layers:31, std:2.7467752464899187e-13\n",
      "layers:32, std:9.769905018460964e-14\n",
      "layers:33, std:4.241495799332459e-14\n",
      "layers:34, std:1.7515138712770502e-14\n",
      "layers:35, std:7.236643772559007e-15\n",
      "layers:36, std:2.754834900508315e-15\n",
      "layers:37, std:1.1144129789778683e-15\n",
      "layers:38, std:4.665531059463979e-16\n",
      "layers:39, std:1.9115909698550995e-16\n",
      "layers:40, std:7.619770750645757e-17\n",
      "layers:41, std:3.072803922067087e-17\n",
      "layers:42, std:1.2483409449233818e-17\n",
      "layers:43, std:5.584388959574096e-18\n",
      "layers:44, std:2.1434822202953987e-18\n",
      "layers:45, std:7.595289223723423e-19\n",
      "layers:46, std:3.2265934966493105e-19\n",
      "layers:47, std:1.3344637281088623e-19\n",
      "layers:48, std:5.3107111745049776e-20\n",
      "layers:49, std:2.2780597690562997e-20\n",
      "layers:50, std:8.359985679091704e-21\n",
      "layers:51, std:3.9317994777919466e-21\n",
      "layers:52, std:1.5884939396056445e-21\n",
      "layers:53, std:6.692804467155623e-22\n",
      "layers:54, std:2.50186769085188e-22\n",
      "layers:55, std:9.636928028749065e-23\n",
      "layers:56, std:3.658637481940995e-23\n",
      "layers:57, std:1.6094038843453288e-23\n",
      "layers:58, std:5.9940156212066554e-24\n",
      "layers:59, std:2.318952871927601e-24\n",
      "layers:60, std:1.0149355230600308e-24\n",
      "layers:61, std:3.725882746515202e-25\n",
      "layers:62, std:1.5864273835692032e-25\n",
      "layers:63, std:6.342765234207592e-26\n",
      "layers:64, std:2.5224673312873427e-26\n",
      "layers:65, std:9.726536324090501e-27\n",
      "layers:66, std:4.279852752153836e-27\n",
      "layers:67, std:1.9163428577170706e-27\n",
      "layers:68, std:7.324901876032613e-28\n",
      "layers:69, std:2.8120613858969833e-28\n",
      "layers:70, std:1.205051958790663e-28\n",
      "layers:71, std:4.825252567910731e-29\n",
      "layers:72, std:1.940833482427978e-29\n",
      "layers:73, std:8.741473273844702e-30\n",
      "layers:74, std:3.514195092800203e-30\n",
      "layers:75, std:1.4935882943299421e-30\n",
      "layers:76, std:6.140757098017652e-31\n",
      "layers:77, std:2.670449509983366e-31\n",
      "layers:78, std:1.0969915466901928e-31\n",
      "layers:79, std:4.27141762634355e-32\n",
      "layers:80, std:1.6600780848901534e-32\n",
      "layers:81, std:6.380023507078797e-33\n",
      "layers:82, std:2.8073887096887288e-33\n",
      "layers:83, std:1.0360547313693515e-33\n",
      "layers:84, std:3.7414045161817074e-34\n",
      "layers:85, std:1.4564609187203345e-34\n",
      "layers:86, std:5.589328127394273e-35\n",
      "layers:87, std:2.2138920812051178e-35\n",
      "layers:88, std:8.807056367467975e-36\n",
      "layers:89, std:3.4322357983375034e-36\n",
      "layers:90, std:1.3510373636296774e-36\n",
      "layers:91, std:5.099645728766647e-37\n",
      "layers:92, std:1.866537738063688e-37\n",
      "layers:93, std:7.515124988336379e-38\n",
      "layers:94, std:2.6169094678434883e-38\n",
      "layers:95, std:1.1516208492751249e-38\n",
      "layers:96, std:4.344909458737922e-39\n",
      "layers:97, std:1.594351149859454e-39\n",
      "layers:98, std:5.721221370145363e-40\n",
      "layers:99, std:2.4877251637158477e-40\n",
      "tensor([[0.0000e+00, 2.1161e-41, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 5.1799e-41, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 5.8066e-41, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 下面的代码打印一个网络的每个网络层的输出，在没有进行初始化时，数据尺度越来越小。\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "set_seed(1)  # 设置随机种子\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, neural_num, layers=100):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(neural_num, neural_num, bias=False) for i in range(layers)])\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm1d(neural_num) for i in range(layers)])\n",
    "        self.neural_num = neural_num\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        for (i, linear), bn in zip(enumerate(self.linears), self.bns):\n",
    "            x = linear(x)\n",
    "            # x = bn(x)\n",
    "            x = torch.relu(x)\n",
    "\n",
    "            if torch.isnan(x.std()):\n",
    "                print(\"output is nan in {} layers\".format(i))\n",
    "                break\n",
    "\n",
    "            print(\"layers:{}, std:{}\".format(i, x.std().item()))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "\n",
    "                # method 1\n",
    "                # nn.init.normal_(m.weight.data, std=1)    # normal: mean=0, std=1\n",
    "\n",
    "                # method 2 kaiming\n",
    "                nn.init.kaiming_normal_(m.weight.data)\n",
    "\n",
    "\n",
    "neural_nums = 256\n",
    "layer_nums = 100\n",
    "batch_size = 16\n",
    "\n",
    "net = MLP(neural_nums, layer_nums)\n",
    "# net.initialize()\n",
    "\n",
    "inputs = torch.randn((batch_size, neural_nums))  # normal: mean=0, std=1\n",
    "\n",
    "output = net(inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们不对网络层进行权值初始化，而是在每个激活函数层之前使用 bn 层，查看数据的标准差尺度稳定在 [0.58, 0.59]。因此 Batch Normalization 可以不用精心设计权值初始化。\n",
    "下面以人民币二分类实验中的 LeNet 为例，添加 bn 层，对比不带 bn 层的网络和带 bn 层的网络的训练过程。\n",
    "不带 bn 层的网络，并且使用 kaiming 初始化权值，训练过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet_bn(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(LeNet_bn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=6)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=16)\n",
    "\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.bn3 = nn.BatchNorm1d(num_features=120)\n",
    "\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = F.max_pool2d(out, 2)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = F.max_pool2d(out, 2)\n",
    "\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = self.bn3(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization in PyTorch\n",
    "在 PyTorch 中，有 3 个 Batch Normalization 类\n",
    "\n",
    "nn.BatchNorm1d()，输入数据的形状是 $B \\times C \\times 1D_feature$\n",
    "\n",
    "nn.BatchNorm2d()，输入数据的形状是 $B \\times C \\times 2D_feature$\n",
    "\n",
    "nn.BatchNorm3d()，输入数据的形状是 $B \\times C \\times 3D_feature$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "```\n",
    "```\n",
    "参数：\n",
    "    num_features：一个样本的特征数量，这个参数最重要\n",
    "    eps：在进行标准化操作时的分布修正项\n",
    "    momentum：指数加权平均估计当前的均值和方差\n",
    "    affine：是否需要 affine transform，默认为 True\n",
    "    track_running_stats：True 为训练状态，此时均值和方差会根据每个 mini-batch 改变。False 为测试状态，此时均值和方差会固定\n",
    "\n",
    "```\n",
    "主要属性：\n",
    "    runninng_mean：均值\n",
    "\n",
    "    running_var：方差 \n",
    "\n",
    "    weight：affine transform 中的 $\\gamma$\n",
    "    \n",
    "    bias：affine transform 中的 $\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.BatchNorm1d()\n",
    "输入数据的形状是 $B \\times C \\times 1D_feature$。在下面的例子中，数据的维度是：(3, 5, 1)，表示一个 mini-batch 有 3 个样本，每个样本有 5 个特征，每个特征的维度是 1。那么就会计算 5 个均值和方差，分别对应每个特征维度。momentum 设置为 0.3，第一次的均值和方差默认为 0 和 1。输入两次 mini-batch 的数据。\n",
    "\n",
    "![image](https://image.zhangxiann.com/20200706220302.png \"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data:\n",
      "tensor([[[1.],\n",
      "         [2.],\n",
      "         [3.],\n",
      "         [4.],\n",
      "         [5.]],\n",
      "\n",
      "        [[1.],\n",
      "         [2.],\n",
      "         [3.],\n",
      "         [4.],\n",
      "         [5.]],\n",
      "\n",
      "        [[1.],\n",
      "         [2.],\n",
      "         [3.],\n",
      "         [4.],\n",
      "         [5.]]]) shape is torch.Size([3, 5, 1])\n",
      "\n",
      "iteration:0, running mean: tensor([0.3000, 0.6000, 0.9000, 1.2000, 1.5000]) \n",
      "iteration:0, running var:tensor([0.7000, 0.7000, 0.7000, 0.7000, 0.7000]) \n",
      "iteration:0, 第二个特征的running mean: 0.6 \n",
      "iteration:0, 第二个特征的running var:0.7\n",
      "\n",
      "iteration:1, running mean: tensor([0.5100, 1.0200, 1.5300, 2.0400, 2.5500]) \n",
      "iteration:1, running var:tensor([0.4900, 0.4900, 0.4900, 0.4900, 0.4900]) \n",
      "iteration:1, 第二个特征的running mean: 1.02 \n",
      "iteration:1, 第二个特征的running var:0.48999999999999994\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "num_features = 5\n",
    "momentum = 0.3\n",
    "\n",
    "features_shape = (1)\n",
    "\n",
    "feature_map = torch.ones(features_shape)                                                    # 1D\n",
    "feature_maps = torch.stack([feature_map*(i+1) for i in range(num_features)], dim=0)         # 2D\n",
    "feature_maps_bs = torch.stack([feature_maps for i in range(batch_size)], dim=0)             # 3D\n",
    "\n",
    "print(\"input data:\\n{} shape is {}\".format(feature_maps_bs, feature_maps_bs.shape))\n",
    "\n",
    "bn = nn.BatchNorm1d(num_features=num_features, momentum=momentum)\n",
    "\n",
    "running_mean, running_var = 0, 1\n",
    "mean_t, var_t = 2, 0\n",
    "for i in range(2):\n",
    "    outputs = bn(feature_maps_bs)\n",
    "\n",
    "    print(\"\\niteration:{}, running mean: {} \".format(i, bn.running_mean))\n",
    "    print(\"iteration:{}, running var:{} \".format(i, bn.running_var))\n",
    "\n",
    "\n",
    "\n",
    "    running_mean = (1 - momentum) * running_mean + momentum * mean_t\n",
    "    running_var = (1 - momentum) * running_var + momentum * var_t\n",
    "\n",
    "    print(\"iteration:{}, 第二个特征的running mean: {} \".format(i, running_mean))\n",
    "    print(\"iteration:{}, 第二个特征的running var:{}\".format(i, running_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.BatchNorm2d()\n",
    "输入数据的形状是 $B \\times C \\times 2D_feature$。在下面的例子中，数据的维度是：(3, 3, 2, 2)，表示一个 mini-batch 有 3 个样本，每个样本有 3 个特征，每个特征的维度是 $1 \\times 2$。那么就会计算 3 个均值和方差，分别对应每个特征维度。momentum 设置为 0.3，第一次的均值和方差默认为 0 和 1。输入两次 mini-batch 的数据。\n",
    "![image](https://image.zhangxiann.com/20200706220726.png \"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter:0, running_mean: tensor([0.3000, 0.6000, 0.9000])\n",
      "iter:0, running_var: tensor([0.7000, 0.7000, 0.7000])\n",
      "iter:0, weight: [1. 1. 1.]\n",
      "iter:0, bias: [0. 0. 0.]\n",
      "\n",
      "iter:1, running_mean: tensor([0.5100, 1.0200, 1.5300])\n",
      "iter:1, running_var: tensor([0.4900, 0.4900, 0.4900])\n",
      "iter:1, weight: [1. 1. 1.]\n",
      "iter:1, bias: [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "num_features = 3\n",
    "momentum = 0.3\n",
    "\n",
    "features_shape = (2, 2)\n",
    "\n",
    "feature_map = torch.ones(features_shape)                                                    # 2D\n",
    "feature_maps = torch.stack([feature_map*(i+1) for i in range(num_features)], dim=0)         # 3D\n",
    "feature_maps_bs = torch.stack([feature_maps for i in range(batch_size)], dim=0)             # 4D\n",
    "\n",
    "# print(\"input data:\\n{} shape is {}\".format(feature_maps_bs, feature_maps_bs.shape))\n",
    "\n",
    "bn = nn.BatchNorm2d(num_features=num_features, momentum=momentum)\n",
    "\n",
    "running_mean, running_var = 0, 1\n",
    "\n",
    "for i in range(2):\n",
    "    outputs = bn(feature_maps_bs)\n",
    "\n",
    "    print(\"\\niter:{}, running_mean: {}\".format(i, bn.running_mean))\n",
    "    print(\"iter:{}, running_var: {}\".format(i, bn.running_var))\n",
    "\n",
    "    print(\"iter:{}, weight: {}\".format(i, bn.weight.data.numpy()))\n",
    "    print(\"iter:{}, bias: {}\".format(i, bn.bias.data.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.BatchNorm3d()\n",
    "输入数据的形状是 $B \\times C \\times 3D_feature$。在下面的例子中，数据的维度是：(3, 2, 2, 2, 3)，表示一个 mini-batch 有 3 个样本，每个样本有 2 个特征，每个特征的维度是 $2 \\times 2 \\times 3$。那么就会计算 2 个均值和方差，分别对应每个特征维度。momentum 设置为 0.3，第一次的均值和方差默认为 0 和 1。输入两次 mini-batch 的数据。\n",
    "![image](https://image.zhangxiann.com/20200706221801.png \"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter:0, running_mean.shape: torch.Size([3])\n",
      "iter:0, running_var.shape: torch.Size([3])\n",
      "iter:0, weight.shape: torch.Size([3])\n",
      "iter:0, bias.shape: torch.Size([3])\n",
      "\n",
      "iter:1, running_mean.shape: torch.Size([3])\n",
      "iter:1, running_var.shape: torch.Size([3])\n",
      "iter:1, weight.shape: torch.Size([3])\n",
      "iter:1, bias.shape: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "num_features = 3\n",
    "momentum = 0.3\n",
    "\n",
    "features_shape = (2, 2, 3)\n",
    "\n",
    "feature = torch.ones(features_shape)                                                # 3D\n",
    "feature_map = torch.stack([feature * (i + 1) for i in range(num_features)], dim=0)  # 4D\n",
    "feature_maps = torch.stack([feature_map for i in range(batch_size)], dim=0)         # 5D\n",
    "\n",
    "# print(\"input data:\\n{} shape is {}\".format(feature_maps, feature_maps.shape))\n",
    "\n",
    "bn = nn.BatchNorm3d(num_features=num_features, momentum=momentum)\n",
    "\n",
    "running_mean, running_var = 0, 1\n",
    "\n",
    "for i in range(2):\n",
    "    outputs = bn(feature_maps)\n",
    "\n",
    "    print(\"\\niter:{}, running_mean.shape: {}\".format(i, bn.running_mean.shape))\n",
    "    print(\"iter:{}, running_var.shape: {}\".format(i, bn.running_var.shape))\n",
    "\n",
    "    print(\"iter:{}, weight.shape: {}\".format(i, bn.weight.shape))\n",
    "    print(\"iter:{}, bias.shape: {}\".format(i, bn.bias.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Normalization\n",
    "```\n",
    "提出的原因：Batch Normalization 不适用于变长的网络，如 RNN\n",
    "思路：每个网络层计算均值和方差\n",
    "```\n",
    "![image](https://image.zhangxiann.com/20200707095227.png \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.LayerNorm(normalized_shape, eps=1e-05, elementwise_affine=True)\n",
    "```\n",
    "\n",
    "参数：\n",
    "    normalized_shape：该层特征的形状，可以取$C \\times H \\times W$、$H \\times W$、$W$\n",
    "\n",
    "    eps：标准化时的分母修正项\\\n",
    "\n",
    "    elementwise_affine：是否需要逐个样本 affine transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Normalization\n",
      "torch.Size([2, 3, 4])\n",
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.]]])\n",
      "tensor([[[-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "         [ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "         [ 1.0000,  1.0000,  1.0000,  1.0000]]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 8\n",
    "num_features = 2\n",
    "\n",
    "features_shape = (3, 4)\n",
    "\n",
    "feature_map = torch.ones(features_shape)  # 2D\n",
    "feature_maps = torch.stack([feature_map * (i + 1) for i in range(num_features)], dim=0)  # 3D\n",
    "feature_maps_bs = torch.stack([feature_maps for i in range(batch_size)], dim=0)  # 4D\n",
    "\n",
    "# feature_maps_bs shape is [8, 6, 3, 4],  B * C * H * W\n",
    "# ln = nn.LayerNorm(feature_maps_bs.size()[1:], elementwise_affine=True)\n",
    "# ln = nn.LayerNorm(feature_maps_bs.size()[1:], elementwise_affine=False)\n",
    "# ln = nn.LayerNorm([6, 3, 4])\n",
    "ln = nn.LayerNorm([2, 3, 4])\n",
    "\n",
    "output = ln(feature_maps_bs)\n",
    "\n",
    "print(\"Layer Normalization\")\n",
    "print(ln.weight.shape)\n",
    "print(feature_maps_bs[0, ...])\n",
    "print(output[0, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance Normalization\n",
    "```\n",
    "提出的原因：Batch Normalization 不适用于图像生成。因为在一个 mini-batch 中的图像有不同的风格，不能把这个 batch 里的数据都看作是同一类取标准化。\n",
    "思路：逐个 instance 的 channel 计算均值和方差。也就是每个 feature map 计算一个均值和方差。\n",
    "包括 InstanceNorm1d、InstanceNorm2d、InstanceNorm3d。\n",
    "```\n",
    "```python\n",
    "torch.nn.InstanceNorm1d(num_features, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
    "```\n",
    "```\n",
    "参数：\n",
    "    num_features：一个样本的特征数，这个参数最重要\n",
    "    eps：分母修正项\n",
    "    momentum：指数加权平均估计当前的的均值和方差\n",
    "    affine：是否需要 affine transform\n",
    "    track_running_stats：True 为训练状态，此时均值和方差会根据每个 mini-batch 改变。False 为测试状态，此时均值和方差会固定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面代码中，输入数据的形状是 $B \\times C \\times 2D_feature$，(3, 3, 2, 2)，表示一个 mini-batch 有 3 个样本，每个样本有 3 个特征，每个特征的维度是 $2 \\times 2 $。那么就会计算 $3 \\times 3 $ 个均值和方差，分别对应每个样本的每个特征。\n",
    "\n",
    "![image](https://image.zhangxiann.com/20200707103153.png \"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance Normalization\n",
      "input data:\n",
      "tensor([[[[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[2., 2.],\n",
      "          [2., 2.]],\n",
      "\n",
      "         [[3., 3.],\n",
      "          [3., 3.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[2., 2.],\n",
      "          [2., 2.]],\n",
      "\n",
      "         [[3., 3.],\n",
      "          [3., 3.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[2., 2.],\n",
      "          [2., 2.]],\n",
      "\n",
      "         [[3., 3.],\n",
      "          [3., 3.]]]]) shape is torch.Size([3, 3, 2, 2])\n",
      "torch.Size([3, 3, 2, 2])\n",
      "tensor([[[[-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  1.0000]]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "num_features = 3\n",
    "momentum = 0.3\n",
    "\n",
    "features_shape = (2, 2)\n",
    "\n",
    "feature_map = torch.ones(features_shape)    # 2D\n",
    "feature_maps = torch.stack([feature_map * (i + 1) for i in range(num_features)], dim=0)  # 3D\n",
    "feature_maps_bs = torch.stack([feature_maps for i in range(batch_size)], dim=0)  # 4D\n",
    "\n",
    "print(\"Instance Normalization\")\n",
    "print(\"input data:\\n{} shape is {}\".format(feature_maps_bs, feature_maps_bs.shape))\n",
    "\n",
    "instance_n = nn.InstanceNorm2d(num_features=num_features, momentum=momentum)\n",
    "\n",
    "for i in range(1):\n",
    "    outputs = instance_n(feature_maps_bs)\n",
    "    print(outputs.shape)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Normalization\n",
    "```\n",
    "提出的原因：在小 batch 的样本中，Batch Normalization 估计的值不准。一般用在很大的模型中，这时 batch size 就很小。\n",
    "思路：数据不够，通道来凑。 每个样本的特征分为几组，每组特征分别计算均值和方差。可以看作是 Layer Normalization 的基础上添加了特征分组。\n",
    "注意事项：\n",
    "```\n",
    "\n",
    "不再有 running_mean 和 running_var\n",
    "$\\gamma$ 和 $\\beta$ 为逐通道的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.GroupNorm(num_groups, num_channels, eps=1e-05, affine=True)\n",
    "```\n",
    "```\n",
    "参数：\n",
    "    num_groups：特征的分组数量\n",
    "    num_channels：特征数，通道数。注意 num_channels 要可以整除 num_groups\n",
    "    eps：分母修正项\n",
    "    affine：是否需要 affine transform\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面代码中，输入数据的形状是 $B \\times C \\times 2D_feature$，(2, 4, 3, 3)，表示一个 mini-batch 有 2 个样本，每个样本有 4 个特征，每个特征的维度是 $3 \\times 3 $。num_groups 设置为 2，那么就会计算 $2 \\times (4 \\div 2) $ 个均值和方差，分别对应每个样本的每个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Normalization\n",
      "torch.Size([4])\n",
      "tensor([[[-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000]],\n",
      "\n",
      "        [[ 1.0000,  1.0000],\n",
      "         [ 1.0000,  1.0000]],\n",
      "\n",
      "        [[-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000]],\n",
      "\n",
      "        [[ 1.0000,  1.0000],\n",
      "         [ 1.0000,  1.0000]]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_features = 4\n",
    "num_groups = 2   \n",
    "features_shape = (2, 2)\n",
    "\n",
    "feature_map = torch.ones(features_shape)    # 2D\n",
    "feature_maps = torch.stack([feature_map * (i + 1) for i in range(num_features)], dim=0)  # 3D\n",
    "feature_maps_bs = torch.stack([feature_maps * (i + 1) for i in range(batch_size)], dim=0)  # 4D\n",
    "\n",
    "gn = nn.GroupNorm(num_groups, num_features)\n",
    "outputs = gn(feature_maps_bs)\n",
    "\n",
    "print(\"Group Normalization\")\n",
    "print(gn.weight.shape)\n",
    "print(outputs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ee8edfac98a68d22388d5c9d2c882fbbce04e225b817d7a8b0ca882dcedeab3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
