{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络模型的创建步骤\n",
    "创建模型有 2 个要素：构建子模块和拼接子模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结\n",
    "```\n",
    "一个 module 里可包含多个子 module。比如 LeNet 是一个 Module，里面包括多个卷积层、池化层、全连接层等子 module\n",
    "一个 module 相当于一个运算，必须实现 forward() 函数\n",
    "每个 module 都有 8 个字典管理自己的属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    # 子模块创建\n",
    "    def __init__(self, classes):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, classes)\n",
    "    # 子模块拼接\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型容器\n",
    "```\n",
    "除了上述的模块之外，还有一个重要的概念是模型容器 (Containers)，常用的容器有 3 个，这些容器都是继承自nn.Module。\n",
    "    nn.Sequetial：按照顺序包装多个网络层\n",
    "    nn.ModuleList：像 python 的 list 一样包装多个网络层，可以迭代\n",
    "    nn.ModuleDict：像 python 的 dict一样包装多个网络层，通过 (key, value) 的方式为每个网络层指定名称。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Sequetial\n",
    "```\n",
    "在传统的机器学习中，有一个步骤是特征工程，我们需要从数据中认为地提取特征，然后把特征输入到分类器中预测。在深度学习的时代，特征工程的概念被弱化了，特征提取和分类器这两步被融合到了一个神经网络中。在卷积神经网络中，前面的卷积层以及池化层可以认为是特征提取部分，而后面的全连接层可以认为是分类器部分。比如 LeNet 就可以分为特征提取和分类器两部分，这 2 部分都可以分别使用 nn.Seuqtial 来包装。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetSequetial(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2, 2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetSequentialOrderDict(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(LeNetSequentialOrderDict, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(OrderedDict({\n",
    "            'conv1': nn.Conv2d(3, 6, 5),\n",
    "            'relu1': nn.ReLU(inplace=True),\n",
    "            'pool1': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            'conv2': nn.Conv2d(6, 16, 5),\n",
    "            'relu2': nn.ReLU(inplace=True),\n",
    "            'pool2': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        }))\n",
    "\n",
    "        self.classifier = nn.Sequential(OrderedDict({\n",
    "            'fc1': nn.Linear(16*5*5, 120),\n",
    "            'relu3': nn.ReLU(),\n",
    "\n",
    "            'fc2': nn.Linear(120, 84),\n",
    "            'relu4': nn.ReLU(inplace=True),\n",
    "\n",
    "            'fc3': nn.Linear(84, classes),\n",
    "        }))\n",
    "        ...\n",
    "        ...\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结\n",
    "```\n",
    "nn.Sequetial是nn.Module的容器，用于按顺序包装一组网络层，有以下两个特性。\n",
    "顺序性：各网络层之间严格按照顺序构建，我们在构建网络时，一定要注意前后网络层之间输入和输出数据之间的形状是否匹配\n",
    "自带forward()函数：在nn.Sequetial的forward()函数里通过 for 循环依次读取每个网络层，执行前向传播运算。这使得我们我们构建的模型更加简洁"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.ModuleList\n",
    "```\n",
    "nn.ModuleList是nn.Module的容器，用于包装一组网络层，以迭代的方式调用网络层，主要有以下 3 个方法：\n",
    "append()：在 ModuleList 后面添加网络层\n",
    "extend()：拼接两个 ModuleList\n",
    "insert()：在 ModuleList 的指定位置中插入网络层\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (5): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (6): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (7): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (8): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (9): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (10): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (11): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (12): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (13): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (14): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (15): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (16): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (17): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (18): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (19): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[ 0.3381, -0.1413,  0.3761,  0.0071,  0.3260,  0.3484, -0.0247,  0.0686,\n",
      "          0.1936, -0.2266],\n",
      "        [ 0.3381, -0.1413,  0.3761,  0.0071,  0.3260,  0.3484, -0.0247,  0.0686,\n",
      "          0.1936, -0.2266],\n",
      "        [ 0.3381, -0.1413,  0.3761,  0.0071,  0.3260,  0.3484, -0.0247,  0.0686,\n",
      "          0.1936, -0.2266],\n",
      "        [ 0.3381, -0.1413,  0.3761,  0.0071,  0.3260,  0.3484, -0.0247,  0.0686,\n",
      "          0.1936, -0.2266],\n",
      "        [ 0.3381, -0.1413,  0.3761,  0.0071,  0.3260,  0.3484, -0.0247,  0.0686,\n",
      "          0.1936, -0.2266],\n",
      "        [ 0.3381, -0.1413,  0.3761,  0.0071,  0.3260,  0.3484, -0.0247,  0.0686,\n",
      "          0.1936, -0.2266],\n",
      "        [ 0.3381, -0.1413,  0.3761,  0.0071,  0.3260,  0.3484, -0.0247,  0.0686,\n",
      "          0.1936, -0.2266],\n",
      "        [ 0.3381, -0.1413,  0.3761,  0.0071,  0.3260,  0.3484, -0.0247,  0.0686,\n",
      "          0.1936, -0.2266],\n",
      "        [ 0.3381, -0.1413,  0.3761,  0.0071,  0.3260,  0.3484, -0.0247,  0.0686,\n",
      "          0.1936, -0.2266],\n",
      "        [ 0.3381, -0.1413,  0.3761,  0.0071,  0.3260,  0.3484, -0.0247,  0.0686,\n",
      "          0.1936, -0.2266]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class ModuleList(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModuleList, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(20)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, linear in enumerate(self.linears):\n",
    "            x = linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = ModuleList()\n",
    "\n",
    "print(net)\n",
    "\n",
    "fake_data = torch.ones((10, 10))\n",
    "\n",
    "output = net(fake_data)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.ModuleDict\n",
    "```\n",
    "nn.ModuleDict是nn.Module的容器，用于包装一组网络层，以索引的方式调用网络层，主要有以下 5 个方法：\n",
    "clear()：清空  ModuleDict\n",
    "items()：返回可迭代的键值对 (key, value)\n",
    "keys()：返回字典的所有 key\n",
    "values()：返回字典的所有 value\n",
    "pop()：返回一对键值，并从字典中删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[5.1309e-01, 8.7948e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           5.3402e-01, 0.0000e+00],\n",
      "          [2.4881e-01, 2.5132e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           9.3012e-01, 0.0000e+00],\n",
      "          [1.3450e-01, 0.0000e+00, 8.5232e-01,  ..., 9.7109e-01,\n",
      "           9.3308e-01, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 3.8770e-01,  ..., 0.0000e+00,\n",
      "           6.4879e-02, 5.8475e-01],\n",
      "          [4.8913e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[1.2024e+00, 4.5478e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           3.1379e-01, 4.0610e-01],\n",
      "          [0.0000e+00, 5.3054e-01, 5.9884e-01,  ..., 5.3529e-01,\n",
      "           7.5935e-01, 3.3993e-01],\n",
      "          [0.0000e+00, 8.4214e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.0221e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 6.0060e-01,  ..., 6.8416e-01,\n",
      "           5.3994e-02, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.9825e-01,\n",
      "           0.0000e+00, 4.1982e-01],\n",
      "          [4.8982e-01, 6.8333e-01, 5.1325e-01,  ..., 0.0000e+00,\n",
      "           1.1279e+00, 6.2584e-01]],\n",
      "\n",
      "         [[0.0000e+00, 1.1199e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 8.8777e-02],\n",
      "          [1.6747e-01, 0.0000e+00, 3.0554e-01,  ..., 0.0000e+00,\n",
      "           5.5093e-01, 3.2973e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           5.2774e-01, 2.4344e-01],\n",
      "          ...,\n",
      "          [5.6261e-01, 0.0000e+00, 1.2595e-02,  ..., 8.0949e-01,\n",
      "           2.9010e-01, 2.6283e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 9.6278e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 4.7243e-01,  ..., 0.0000e+00,\n",
      "           2.2502e-01, 8.5625e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 2.3959e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.8602e-01, 4.4297e-01],\n",
      "          [0.0000e+00, 1.2076e-01, 2.6381e-01,  ..., 0.0000e+00,\n",
      "           3.2346e-01, 6.9758e-01],\n",
      "          [4.7096e-01, 0.0000e+00, 1.9441e-01,  ..., 2.0236e-01,\n",
      "           4.1218e-01, 4.7005e-01],\n",
      "          ...,\n",
      "          [1.5195e-01, 0.0000e+00, 0.0000e+00,  ..., 3.4412e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.7957e-03, 2.2069e-01, 0.0000e+00,  ..., 6.7677e-01,\n",
      "           0.0000e+00, 2.5063e-01],\n",
      "          [0.0000e+00, 6.8657e-01, 6.4310e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3082e+00,\n",
      "           8.1180e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 3.4613e-01, 2.6535e-01,  ..., 0.0000e+00,\n",
      "           2.9247e-01, 1.2113e+00],\n",
      "          [1.9284e-01, 0.0000e+00, 0.0000e+00,  ..., 4.7667e-01,\n",
      "           0.0000e+00, 7.4755e-01],\n",
      "          ...,\n",
      "          [1.8770e-01, 2.8304e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.1661e-01, 0.0000e+00, 1.1373e-01,  ..., 0.0000e+00,\n",
      "           4.2173e-01, 7.1307e-01],\n",
      "          [0.0000e+00, 4.7169e-01, 6.0350e-01,  ..., 3.3470e-01,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[9.7083e-01, 0.0000e+00, 1.4639e+00,  ..., 7.8282e-01,\n",
      "           0.0000e+00, 5.4544e-02],\n",
      "          [0.0000e+00, 1.0397e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.6808e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 2.2359e-01,  ..., 3.5191e-01,\n",
      "           4.8753e-01, 3.8118e-01],\n",
      "          [5.5602e-01, 0.0000e+00, 1.7590e-01,  ..., 0.0000e+00,\n",
      "           5.5148e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.0334e-01, 2.1371e-01]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 0.0000e+00, 7.8794e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.2243e+00, 4.6932e-01, 3.5842e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 2.2409e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 8.8909e-02,  ..., 0.0000e+00,\n",
      "           2.3413e-01, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 1.2698e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.9513e-01, 0.0000e+00, 1.7781e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 6.3323e-01,  ..., 2.7090e-01,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 3.3415e-01,  ..., 5.0460e-01,\n",
      "           5.9207e-01, 9.9789e-02],\n",
      "          [1.2224e-01, 0.0000e+00, 4.6099e-02,  ..., 2.9543e-01,\n",
      "           7.9490e-01, 0.0000e+00],\n",
      "          [8.5428e-01, 1.9129e-01, 0.0000e+00,  ..., 9.7042e-02,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.7638e-01,\n",
      "           8.8105e-01, 0.0000e+00],\n",
      "          [6.6670e-01, 0.0000e+00, 2.8437e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 9.5759e-02],\n",
      "          [2.9376e-01, 0.0000e+00, 0.0000e+00,  ..., 4.6976e-01,\n",
      "           4.7893e-01, 5.2050e-01]],\n",
      "\n",
      "         [[4.7744e-01, 1.4709e-01, 6.4324e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 5.3502e-01,  ..., 9.6765e-02,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.4569e-01, 6.4560e-03, 4.3886e-01,  ..., 3.6972e-01,\n",
      "           0.0000e+00, 2.5935e-02],\n",
      "          ...,\n",
      "          [5.0904e-01, 0.0000e+00, 3.7904e-01,  ..., 0.0000e+00,\n",
      "           5.7042e-01, 0.0000e+00],\n",
      "          [3.2848e-01, 5.8430e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.0606e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 8.7190e-02, 0.0000e+00,  ..., 1.9190e-01,\n",
      "           0.0000e+00, 1.2689e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.6837e-01, 0.0000e+00, 2.1567e-01,  ..., 2.1903e-01,\n",
      "           6.4899e-01, 2.9972e-01],\n",
      "          [0.0000e+00, 2.6061e-01, 5.2808e-01,  ..., 0.0000e+00,\n",
      "           6.7002e-02, 3.3315e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 5.1322e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 5.4696e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 3.9484e-01,  ..., 7.0735e-01,\n",
      "           2.3132e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.6002e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           9.4626e-02, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 5.1934e-01, 0.0000e+00,  ..., 3.4502e-01,\n",
      "           4.5432e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.2578e+00,\n",
      "           0.0000e+00, 5.5129e-02],\n",
      "          [0.0000e+00, 8.4923e-01, 3.8863e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 4.3877e-01],\n",
      "          ...,\n",
      "          [7.2106e-01, 5.2685e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.4137e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 5.8135e-01],\n",
      "          [1.6603e-01, 0.0000e+00, 4.0609e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 2.1046e-02]],\n",
      "\n",
      "         [[3.5454e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           5.0369e-01, 2.0854e-01],\n",
      "          [2.6217e-01, 3.3528e-03, 0.0000e+00,  ..., 7.5776e-02,\n",
      "           7.5299e-01, 0.0000e+00],\n",
      "          [1.1506e+00, 2.1093e-01, 1.3471e-01,  ..., 8.9682e-01,\n",
      "           3.3164e-03, 6.3119e-01],\n",
      "          ...,\n",
      "          [1.2529e+00, 6.3751e-02, 1.0835e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.7000e-01, 8.2536e-01, 0.0000e+00,  ..., 1.0819e+00,\n",
      "           1.9804e-01, 9.5784e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 6.0213e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 3.2351e-01]]],\n",
      "\n",
      "\n",
      "        [[[4.9281e-01, 2.2068e-01, 1.6260e-01,  ..., 8.9369e-02,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.9536e-01, 8.3226e-02, 7.3452e-02,  ..., 9.8820e-02,\n",
      "           2.2629e-01, 0.0000e+00],\n",
      "          [1.5351e-01, 3.5380e-01, 0.0000e+00,  ..., 5.3936e-03,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 1.5336e+00, 2.5184e-01,  ..., 0.0000e+00,\n",
      "           1.2253e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           5.5998e-01, 0.0000e+00],\n",
      "          [2.5435e-02, 0.0000e+00, 0.0000e+00,  ..., 1.1572e+00,\n",
      "           8.4616e-01, 0.0000e+00]],\n",
      "\n",
      "         [[6.8646e-02, 0.0000e+00, 5.5500e-01,  ..., 6.9381e-01,\n",
      "           0.0000e+00, 1.0769e-02],\n",
      "          [8.8194e-01, 0.0000e+00, 6.5914e-01,  ..., 2.8807e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.0138e+00, 7.0110e-01, 0.0000e+00,  ..., 3.8780e-01,\n",
      "           4.5341e-01, 7.9910e-01],\n",
      "          ...,\n",
      "          [6.8619e-02, 2.5667e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.6397e+00, 2.7950e-01],\n",
      "          [3.1358e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 3.3216e-01],\n",
      "          [3.5287e-01, 2.2787e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 3.0095e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.3180e-02, 0.0000e+00],\n",
      "          [0.0000e+00, 1.8209e-01, 1.3731e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 2.7767e-01],\n",
      "          [0.0000e+00, 1.6947e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [8.9032e-01, 0.0000e+00, 7.0618e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.7348e-01],\n",
      "          [4.7239e-01, 3.2743e-01, 0.0000e+00,  ..., 1.6182e-01,\n",
      "           5.1047e-01, 0.0000e+00],\n",
      "          [2.7729e-01, 9.4229e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 4.4429e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.3914e-01, 2.4869e-01, 1.1049e-01,  ..., 9.4035e-01,\n",
      "           0.0000e+00, 2.9521e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.0896e-01,\n",
      "           0.0000e+00, 7.1413e-02],\n",
      "          [3.4706e-01, 4.0988e-01, 4.8231e-02,  ..., 7.8510e-02,\n",
      "           8.0689e-02, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.3822e-01, 0.0000e+00, 2.3044e-01,  ..., 1.4349e-02,\n",
      "           0.0000e+00, 2.1433e-01],\n",
      "          [5.3260e-01, 0.0000e+00, 0.0000e+00,  ..., 2.6336e-01,\n",
      "           0.0000e+00, 4.4976e-01],\n",
      "          [4.9959e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 9.2379e-03]],\n",
      "\n",
      "         [[5.6173e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           2.3555e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 1.3732e-02, 0.0000e+00,  ..., 1.8784e-02,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.2528e-01, 0.0000e+00, 1.9838e-01,  ..., 0.0000e+00,\n",
      "           7.0380e-01, 5.2602e-01],\n",
      "          ...,\n",
      "          [3.3506e-01, 0.0000e+00, 0.0000e+00,  ..., 4.9888e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.6679e-01, 0.0000e+00, 9.1067e-01,  ..., 3.3906e-01,\n",
      "           6.1468e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           4.5748e-02, 0.0000e+00]],\n",
      "\n",
      "         [[1.4283e-02, 8.5896e-01, 0.0000e+00,  ..., 6.0455e-01,\n",
      "           2.3209e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 1.3589e-02, 1.1524e-01,  ..., 0.0000e+00,\n",
      "           5.6586e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 6.4649e-04, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           8.7963e-01, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 1.3012e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 7.5428e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 3.7500e-01],\n",
      "          [1.1321e+00, 4.7687e-01, 9.4144e-01,  ..., 4.5171e-01,\n",
      "           7.9570e-02, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[7.9291e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.0447e-01, 0.0000e+00],\n",
      "          [1.2698e-01, 0.0000e+00, 0.0000e+00,  ..., 5.7569e-01,\n",
      "           4.7598e-01, 8.3895e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.4303e-01,\n",
      "           7.2000e-01, 0.0000e+00],\n",
      "          ...,\n",
      "          [7.0520e-01, 7.9775e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 2.3477e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 7.6995e-03]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           2.6270e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.5217e-01, 0.0000e+00, 0.0000e+00,  ..., 2.0293e-01,\n",
      "           0.0000e+00, 2.4557e-01],\n",
      "          ...,\n",
      "          [2.7147e-01, 5.5136e-01, 0.0000e+00,  ..., 4.8263e-01,\n",
      "           0.0000e+00, 3.4460e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.8254e-01,\n",
      "           0.0000e+00, 6.8014e-01],\n",
      "          [1.5804e-01, 3.8829e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 3.5282e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.6542e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           7.3012e-02, 0.0000e+00],\n",
      "          [0.0000e+00, 2.6189e-01, 3.5147e-01,  ..., 1.8316e-01,\n",
      "           6.8764e-01, 2.6012e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 7.2225e-01, 0.0000e+00,  ..., 6.5614e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 2.2727e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.7308e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 9.3316e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.4153e-01, 3.3818e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.7095e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 2.0289e-01],\n",
      "          ...,\n",
      "          [7.0049e-02, 5.0100e-01, 0.0000e+00,  ..., 1.0498e-01,\n",
      "           0.0000e+00, 5.1220e-01],\n",
      "          [0.0000e+00, 5.5710e-01, 2.7703e-01,  ..., 1.3196e-01,\n",
      "           2.7258e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 1.1268e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.6424e-02, 8.3057e-02]],\n",
      "\n",
      "         [[2.6486e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.6950e-01, 0.0000e+00, 6.6432e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 8.6701e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 5.8021e-01],\n",
      "          ...,\n",
      "          [8.3679e-03, 0.0000e+00, 0.0000e+00,  ..., 5.6699e-01,\n",
      "           0.0000e+00, 7.4436e-01],\n",
      "          [3.0604e-01, 0.0000e+00, 0.0000e+00,  ..., 6.0207e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.0426e+00, 0.0000e+00, 4.9023e-02,  ..., 7.8178e-01,\n",
      "           2.3787e-01, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 2.8402e-01, 0.0000e+00,  ..., 6.1484e-01,\n",
      "           7.7422e-01, 0.0000e+00],\n",
      "          [3.7326e-02, 3.4326e-01, 4.6192e-01,  ..., 3.4653e-02,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.1356e-01, 3.2410e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.5932e-02, 5.5369e-01],\n",
      "          ...,\n",
      "          [1.1681e-01, 0.0000e+00, 2.4164e-01,  ..., 1.3319e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.0298e-01, 1.9213e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           3.3183e-01, 3.7358e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.2220e-01,\n",
      "           0.0000e+00, 0.0000e+00]]]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class ModuleDict(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModuleDict, self).__init__()\n",
    "        self.choices = nn.ModuleDict({\n",
    "            'conv': nn.Conv2d(10, 10, 3),\n",
    "            'pool': nn.MaxPool2d(3)\n",
    "        })\n",
    "\n",
    "        self.activations = nn.ModuleDict({\n",
    "            'relu': nn.ReLU(),\n",
    "            'prelu': nn.PReLU()\n",
    "        })\n",
    "\n",
    "    def forward(self, x, choice, act):\n",
    "        x = self.choices[choice](x)\n",
    "        x = self.activations[act](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = ModuleDict()\n",
    "\n",
    "fake_img = torch.randn((4, 10, 32, 32))\n",
    "\n",
    "output = net(fake_img, 'conv', 'relu')\n",
    "# output = net(fake_img, 'conv', 'prelu')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 容器总结\n",
    "```\n",
    "nn.Sequetial：顺序性，各网络层之间严格按照顺序执行，常用于 block 构建，在前向传播时的代码调用变得简洁\n",
    "nn.ModuleList：迭代行，常用于大量重复网络构建，通过 for 循环实现重复构建\n",
    "nn.ModuleDict：索引性，常用于可选择的网络层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch 中的 AlexNet\n",
    "```\n",
    "AlexNet 是 Hinton 和他的学生等人在 2012 年提出的卷积神经网络，以高出第二名 10 多个百分点的准确率获得 ImageNet 分类任务冠军，从此卷积神经网络开始在世界上流行，是划时代的贡献。\n",
    "AlexNet 特点如下：\n",
    "采用 ReLU 替换饱和激活 函数，减轻梯度消失\n",
    "采用 LRN (Local Response Normalization) 对数据进行局部归一化，减轻梯度消失\n",
    "采用 Dropout 提高网络的鲁棒性，增加泛化能力\n",
    "使用 Data Augmentation，包括 TenCrop 和一些色彩修改\n",
    "```\n",
    "![AlexNet](https://image.zhangxiann.com/20200614162004.png \"AlexNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ee8edfac98a68d22388d5c9d2c882fbbce04e225b817d7a8b0ca882dcedeab3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
